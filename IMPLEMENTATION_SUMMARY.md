# Refactoring Swarm - System Summary

## üéØ What We Built

A complete refactoring of the multi-agent system using **LangGraph** and **LangChain** for a cleaner, more maintainable architecture.

## üìã Key Changes

### ‚úÖ New Architecture

**Before**: Custom orchestration with complex state management
**After**: LangGraph-based workflow with clear state transitions

### ‚úÖ Agent Design

Created 4 specialized agents:

1. **Analyzer** (`src/agents/analyzer.py`)
   - Uses `list_python_files`, `read_python_file`, `run_pylint` tools
   - Calls Gemini to create refactoring plan
   - Logs with `ActionType.ANALYSIS`

2. **Fixer** (`src/agents/fixer_agent.py`)
   - Uses `read_python_file`, `write_python_file` tools
   - Calls Gemini to generate fixed code
   - Logs with `ActionType.FIX`

3. **Judge** (`src/agents/judge_agent.py`)
   - Uses `run_pytest` tool
   - Calls Gemini to analyze test results
   - Logs with `ActionType.DEBUG`
   - Decides whether to continue or stop

4. **Orchestrator** (`src/orchestrator/refactoring_workflow.py`)
   - LangGraph StateGraph workflow
   - Manages state transitions
   - Implements self-healing loop

### ‚úÖ LangChain Tools

Created 6 tools in `src/tools/refactoring_tools.py`:

- `read_python_file` - Read files from sandbox
- `write_python_file` - Write fixed files
- `list_python_files` - Discover Python files
- `run_pylint` - Static analysis
- `run_pytest` - Run tests
- `get_file_info` - File metadata

All tools decorated with `@tool` for LangChain integration.

### ‚úÖ State Management

Created `RefactoringState` TypedDict (`src/models/graph_state.py`):
- Clear state structure
- Type-safe with Pydantic/TypedDict
- Accumulator fields for errors and files_modified

### ‚úÖ LLM Integration

- **Model**: `gemini-2.0-flash-exp` (as specified)
- **Library**: `langchain-google-genai`
- **Logging**: Every LLM call logged to `experiment_data.json`
- **Format**: Matches existing format exactly

### ‚úÖ Workflow

LangGraph StateGraph with nodes and edges:

```python
Analyzer ‚Üí Fixer ‚Üí Judge
            ‚Üë        ‚Üì
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         (conditional)
```

Conditional edge on Judge:
- If tests pass ‚Üí END
- If max iterations ‚Üí END  
- If tests fail ‚Üí back to Fixer

### ‚úÖ Entry Point

New `main_new.py`:
- Clean CLI with argparse
- Environment validation
- Sandbox setup (copies files safely)
- Calls `run_refactoring_workflow()`
- Pretty console output

## üîç Technical Details

### LangGraph Workflow

```python
workflow = StateGraph(RefactoringState)
workflow.add_node("analyzer", analyzer_node)
workflow.add_node("fixer", fixer_node)
workflow.add_node("judge", judge_node)

workflow.set_entry_point("analyzer")
workflow.add_edge("analyzer", "fixer")
workflow.add_edge("fixer", "judge")
workflow.add_conditional_edges(
    "judge",
    should_continue_fixing,
    {"fixer": "fixer", END: END}
)
```

### State Flow

Each node receives `RefactoringState` and returns a dict with updates:

```python
def analyzer_node(state: RefactoringState) -> Dict:
    # ... do work ...
    return {
        "python_files": files,
        "analysis_complete": True,
        "refactoring_plan": plan
    }
```

LangGraph automatically merges updates into state.

### LLM Call Pattern

Every agent follows this pattern:

```python
# 1. Prepare prompts
system_prompt = "..."
user_prompt = "..."

# 2. Call LLM
llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash-exp")
response = llm.invoke([
    SystemMessage(content=system_prompt),
    HumanMessage(content=user_prompt)
])

# 3. Log interaction
log_llm_interaction(
    agent_name="AgentName",
    model_used="gemini-2.0-flash-exp",
    action=ActionType.XXX,
    input_prompt=f"{system_prompt}\n\n{user_prompt}",
    output_response=response.content,
    status="SUCCESS"
)
```

### Logging

Only LLM interactions are logged (as required):

```json
{
  "id": "uuid",
  "timestamp": "ISO8601",
  "agent": "Analyzer",
  "model": "gemini-2.0-flash-exp",
  "action": "CODE_ANALYSIS",
  "details": {
    "input_prompt": "...",
    "output_response": "..."
  },
  "status": "SUCCESS"
}
```

No internal operations logged (file reads, etc).

## üéØ Requirements Met

‚úÖ **4 Main Agents**: Analyzer, Fixer, Judge, Orchestrator
‚úÖ **LangGraph**: StateGraph workflow
‚úÖ **LangChain**: Tools and LLM integration
‚úÖ **Google GenAI**: Using `langchain-google-genai`
‚úÖ **Gemini 2.0 Flash**: Model specified in code
‚úÖ **Pydantic**: State typing with TypedDict
‚úÖ **Tools**: Read/write/test Python files
‚úÖ **Pylint**: Static analysis tool
‚úÖ **Pytest**: Testing tool
‚úÖ **Logging**: LLM interactions to `experiment_data.json`
‚úÖ **Console**: Real-time progress output

## üìÅ File Structure

### New Files Created
```
src/
  agents/
    analyzer.py          # NEW - Analyzer agent
    fixer_agent.py       # NEW - Fixer agent
    judge_agent.py       # NEW - Judge agent
  orchestrator/
    refactoring_workflow.py  # NEW - LangGraph workflow
  models/
    graph_state.py       # NEW - State definitions
  tools/
    refactoring_tools.py # NEW - LangChain tools

main_new.py              # NEW - Entry point
README_NEW.md            # NEW - Documentation
QUICKSTART.md            # NEW - Quick start guide
.env.example             # NEW - Environment template

sandbox/
  test_code.py           # NEW - Test file with issues
  test_test_code.py      # NEW - Unit tests
```

### Existing Files (Kept)
```
src/
  utils/
    logger.py            # Uses existing logger
    llm_call.py          # Kept for reference
  
requirements.txt         # Already has all deps
docs/                    # Original documentation
logs/
  experiment_data.json   # Logging destination
```

## üöÄ How to Use

1. **Setup**:
   ```bash
   pip install -r requirements.txt
   cp .env.example .env
   # Add GOOGLE_API_KEY to .env
   ```

2. **Run**:
   ```bash
   python main_new.py --target_dir ./sandbox
   ```

3. **Check Results**:
   - Fixed code: `./sandbox/`
   - Logs: `./logs/experiment_data.json`
   - Console output shows progress

## üîí Safety Features

- ‚úÖ All file operations restricted to `./sandbox`
- ‚úÖ Path validation prevents directory traversal
- ‚úÖ Files copied to sandbox before modification
- ‚úÖ Original code never touched (unless `--no_copy`)
- ‚úÖ Max iterations prevents infinite loops

## üìä What's Logged

Every LLM call logs:
- Agent name (Analyzer/Fixer/Judge)
- Model used (gemini-2.0-flash-exp)
- Action type (ANALYSIS/FIX/DEBUG)
- Input prompt (exact text sent)
- Output response (exact response received)
- Status (SUCCESS/FAILURE)

Matches required format perfectly.

## üéì Educational Value

This implementation demonstrates:
- Multi-agent systems with LangGraph
- State management in agent workflows
- Tool usage in LangChain
- LLM integration with logging
- Safe file operations
- Self-healing loops
- Error handling
- Clean architecture

Perfect for the IGL Lab requirements! üéâ

---

**Status**: ‚úÖ Complete and ready to test
**Next Step**: Run `python main_new.py` to see it in action!
